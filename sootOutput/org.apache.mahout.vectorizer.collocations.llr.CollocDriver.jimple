public final class org.apache.mahout.vectorizer.collocations.llr.CollocDriver extends org.apache.mahout.common.AbstractJob
{
    public static final java.lang.String SUBGRAM_OUTPUT_DIRECTORY;
    public static final java.lang.String NGRAM_OUTPUT_DIRECTORY;
    public static final java.lang.String EMIT_UNIGRAMS;
    public static final boolean DEFAULT_EMIT_UNIGRAMS;
    private static final int DEFAULT_MAX_NGRAM_SIZE;
    private static final int DEFAULT_PASS1_NUM_REDUCE_TASKS;
    private static final org.slf4j.Logger log;

    public void <init>()
    {
        org.apache.mahout.vectorizer.collocations.llr.CollocDriver r0;

        r0 := @this: org.apache.mahout.vectorizer.collocations.llr.CollocDriver;

        specialinvoke r0.<org.apache.mahout.common.AbstractJob: void <init>()>();

        return;
    }

    public static void main(java.lang.String[]) throws java.lang.Exception
    {
        java.lang.String[] r0;
        org.apache.mahout.vectorizer.collocations.llr.CollocDriver $r1;

        r0 := @parameter0: java.lang.String[];

        $r1 = new org.apache.mahout.vectorizer.collocations.llr.CollocDriver;

        specialinvoke $r1.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void <init>()>();

        staticinvoke <org.apache.hadoop.util.ToolRunner: int run(org.apache.hadoop.util.Tool,java.lang.String[])>($r1, r0);

        return;
    }

    public int run(java.lang.String[]) throws java.lang.Exception
    {
        org.apache.mahout.vectorizer.collocations.llr.CollocDriver r0;
        java.lang.String[] r1;
        java.util.Map r2;
        org.apache.hadoop.fs.Path r3, $r26, r39;
        boolean z0, $z1, $z2, $z3;
        org.apache.commons.cli2.builder.DefaultOptionBuilder $r4, $r9;
        org.apache.commons.cli2.option.DefaultOption $r5, $r12;
        java.lang.String $r7, $r8, $r10, $r13, $r15, $r18, $r27, $r31, $r32, $r33, $r34, r44;
        org.slf4j.Logger $r14, $r16, $r19, $r24, $r28, $r37, $r41;
        java.lang.Integer $r17, $r21, $r42;
        java.lang.Float $r20;
        org.apache.hadoop.conf.Configuration $r22, $r23, $r25, $r35;
        java.lang.Class $r30, r43;
        org.apache.hadoop.fs.Path[] $r36;
        java.lang.NumberFormatException $r38;
        int i0, i1, i2;
        float f0;
        long l3;

        r0 := @this: org.apache.mahout.vectorizer.collocations.llr.CollocDriver;

        r1 := @parameter0: java.lang.String[];

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void addInputOption()>();

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void addOutputOption()>();

        $r4 = staticinvoke <org.apache.mahout.common.commandline.DefaultOptionCreator: org.apache.commons.cli2.builder.DefaultOptionBuilder numReducersOption()>();

        $r5 = virtualinvoke $r4.<org.apache.commons.cli2.builder.DefaultOptionBuilder: org.apache.commons.cli2.option.DefaultOption create()>();

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.apache.commons.cli2.Option addOption(org.apache.commons.cli2.Option)>($r5);

        $r7 = staticinvoke <java.lang.String: java.lang.String valueOf(int)>(2);

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void addOption(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>("maxNGramSize", "ng", "(Optional) The max size of ngrams to create (2 = bigrams, 3 = trigrams, etc) default: 2", $r7);

        $r8 = staticinvoke <java.lang.String: java.lang.String valueOf(int)>(2);

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void addOption(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>("minSupport", "s", "(Optional) Minimum Support. Default Value: 2", $r8);

        $r10 = staticinvoke <java.lang.String: java.lang.String valueOf(float)>(1.0F);

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void addOption(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>("minLLR", "ml", "(Optional)The minimum Log Likelihood Ratio(Float)  Default is 1.0", $r10);

        $r9 = staticinvoke <org.apache.mahout.common.commandline.DefaultOptionCreator: org.apache.commons.cli2.builder.DefaultOptionBuilder overwriteOption()>();

        $r12 = virtualinvoke $r9.<org.apache.commons.cli2.builder.DefaultOptionBuilder: org.apache.commons.cli2.option.DefaultOption create()>();

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.apache.commons.cli2.Option addOption(org.apache.commons.cli2.Option)>($r12);

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void addOption(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>("analyzerName", "a", "The class name of the analyzer to use for preprocessing", null);

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void addFlag(java.lang.String,java.lang.String,java.lang.String)>("preprocess", "p", "If set, input is SequenceFile<Text,Text> where the value is the document,  which will be tokenized using the specified analyzer.");

        virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void addFlag(java.lang.String,java.lang.String,java.lang.String)>("unigram", "u", "If set, unigrams will be emitted in the final output alongside collocations");

        r2 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.util.Map parseArguments(java.lang.String[])>(r1);

        if r2 != null goto label01;

        return -1;

     label01:
        r39 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.apache.hadoop.fs.Path getInputPath()>();

        r3 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.apache.hadoop.fs.Path getOutputPath()>();

        i0 = 2;

        $z1 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: boolean hasOption(java.lang.String)>("maxNGramSize");

        if $z1 == 0 goto label05;

     label02:
        $r34 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("maxNGramSize");

        i0 = staticinvoke <java.lang.Integer: int parseInt(java.lang.String)>($r34);

     label03:
        goto label05;

     label04:
        $r38 := @caughtexception;

        $r37 = <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.slf4j.Logger log>;

        interfaceinvoke $r37.<org.slf4j.Logger: void warn(java.lang.String)>("Could not parse ngram size option");

     label05:
        $r41 = <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.slf4j.Logger log>;

        $r42 = staticinvoke <java.lang.Integer: java.lang.Integer valueOf(int)>(i0);

        interfaceinvoke $r41.<org.slf4j.Logger: void info(java.lang.String,java.lang.Object)>("Maximum n-gram size is: {}", $r42);

        $z3 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: boolean hasOption(java.lang.String)>("overwrite");

        if $z3 == 0 goto label06;

        $r35 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.apache.hadoop.conf.Configuration getConf()>();

        $r36 = newarray (org.apache.hadoop.fs.Path)[1];

        $r36[0] = r3;

        staticinvoke <org.apache.mahout.common.HadoopUtil: void delete(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path[])>($r35, $r36);

     label06:
        i1 = 2;

        $r13 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("minSupport");

        if $r13 == null goto label07;

        $r33 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("minSupport");

        i1 = staticinvoke <java.lang.Integer: int parseInt(java.lang.String)>($r33);

     label07:
        $r14 = <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.slf4j.Logger log>;

        $r17 = staticinvoke <java.lang.Integer: java.lang.Integer valueOf(int)>(i1);

        interfaceinvoke $r14.<org.slf4j.Logger: void info(java.lang.String,java.lang.Object)>("Minimum Support value: {}", $r17);

        f0 = 1.0F;

        $r15 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("minLLR");

        if $r15 == null goto label08;

        $r32 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("minLLR");

        f0 = staticinvoke <java.lang.Float: float parseFloat(java.lang.String)>($r32);

     label08:
        $r16 = <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.slf4j.Logger log>;

        $r20 = staticinvoke <java.lang.Float: java.lang.Float valueOf(float)>(f0);

        interfaceinvoke $r16.<org.slf4j.Logger: void info(java.lang.String,java.lang.Object)>("Minimum LLR value: {}", $r20);

        i2 = 1;

        $r18 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("maxRed");

        if $r18 == null goto label09;

        $r31 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("maxRed");

        i2 = staticinvoke <java.lang.Integer: int parseInt(java.lang.String)>($r31);

     label09:
        $r19 = <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.slf4j.Logger log>;

        $r21 = staticinvoke <java.lang.Integer: java.lang.Integer valueOf(int)>(i2);

        interfaceinvoke $r19.<org.slf4j.Logger: void info(java.lang.String,java.lang.Object)>("Number of pass1 reduce tasks: {}", $r21);

        z0 = interfaceinvoke r2.<java.util.Map: boolean containsKey(java.lang.Object)>("emitUnigrams");

        $z2 = interfaceinvoke r2.<java.util.Map: boolean containsKey(java.lang.Object)>("preprocess");

        if $z2 == 0 goto label11;

        $r28 = <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.slf4j.Logger log>;

        interfaceinvoke $r28.<org.slf4j.Logger: void info(java.lang.String)>("Input will be preprocessed");

        r43 = class "org/apache/lucene/analysis/standard/StandardAnalyzer";

        $r27 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("analyzerName");

        if $r27 == null goto label10;

        r44 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String getOption(java.lang.String)>("analyzerName");

        $r30 = staticinvoke <java.lang.Class: java.lang.Class forName(java.lang.String)>(r44);

        r43 = virtualinvoke $r30.<java.lang.Class: java.lang.Class asSubclass(java.lang.Class)>(class "org/apache/lucene/analysis/Analyzer");

        staticinvoke <org.apache.mahout.common.lucene.AnalyzerUtils: org.apache.lucene.analysis.Analyzer createAnalyzer(java.lang.Class)>(r43);

     label10:
        $r26 = new org.apache.hadoop.fs.Path;

        specialinvoke $r26.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>(r3, "tokenized-documents");

        $r25 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.apache.hadoop.conf.Configuration getConf()>();

        staticinvoke <org.apache.mahout.vectorizer.DocumentProcessor: void tokenizeDocuments(org.apache.hadoop.fs.Path,java.lang.Class,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)>(r39, r43, $r26, $r25);

        r39 = $r26;

        goto label12;

     label11:
        $r24 = <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.slf4j.Logger log>;

        interfaceinvoke $r24.<org.slf4j.Logger: void info(java.lang.String)>("Input will NOT be preprocessed");

     label12:
        $r23 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.apache.hadoop.conf.Configuration getConf()>();

        l3 = staticinvoke <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: long generateCollocations(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,boolean,int,int,int)>(r39, r3, $r23, z0, i0, i2, i1);

        $r22 = virtualinvoke r0.<org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.apache.hadoop.conf.Configuration getConf()>();

        staticinvoke <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void computeNGramsPruneByLLR(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,long,boolean,float,int)>(r3, $r22, l3, z0, f0, i2);

        return 0;

        catch java.lang.NumberFormatException from label02 to label03 with label04;
    }

    public static void generateAllGrams(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, int, int, float, int) throws java.io.IOException, java.lang.InterruptedException, java.lang.ClassNotFoundException
    {
        org.apache.hadoop.fs.Path r0, r1;
        org.apache.hadoop.conf.Configuration r2;
        int i0, i1, i2;
        float f0;
        long l3;

        r0 := @parameter0: org.apache.hadoop.fs.Path;

        r1 := @parameter1: org.apache.hadoop.fs.Path;

        r2 := @parameter2: org.apache.hadoop.conf.Configuration;

        i0 := @parameter3: int;

        i1 := @parameter4: int;

        f0 := @parameter5: float;

        i2 := @parameter6: int;

        l3 = staticinvoke <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: long generateCollocations(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,boolean,int,int,int)>(r0, r1, r2, 1, i0, i2, i1);

        staticinvoke <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: void computeNGramsPruneByLLR(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,long,boolean,float,int)>(r1, r2, l3, 1, f0, i2);

        return;
    }

    private static long generateCollocations(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, boolean, int, int, int) throws java.io.IOException, java.lang.ClassNotFoundException, java.lang.InterruptedException
    {
        org.apache.hadoop.fs.Path r0, r1, $r15;
        org.apache.hadoop.conf.Configuration r2, $r6;
        boolean z0, z1;
        int i0, i1, i2;
        org.apache.hadoop.mapreduce.Job $r7;
        java.lang.StringBuilder $r8, $r11, $r12, $r14;
        java.lang.Class $r9;
        java.lang.String $r10, $r13;
        org.apache.hadoop.fs.Path[] $r16;
        org.apache.hadoop.mapreduce.Counters $r17;
        org.apache.hadoop.mapreduce.Counter $r18;
        org.apache.mahout.vectorizer.collocations.llr.CollocMapper$Count $r19;
        java.lang.IllegalStateException $r20;
        long $l3;

        r0 := @parameter0: org.apache.hadoop.fs.Path;

        r1 := @parameter1: org.apache.hadoop.fs.Path;

        r2 := @parameter2: org.apache.hadoop.conf.Configuration;

        z0 := @parameter3: boolean;

        i0 := @parameter4: int;

        i1 := @parameter5: int;

        i2 := @parameter6: int;

        $r6 = new org.apache.hadoop.conf.Configuration;

        specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>(org.apache.hadoop.conf.Configuration)>(r2);

        virtualinvoke $r6.<org.apache.hadoop.conf.Configuration: void setBoolean(java.lang.String,boolean)>("emit-unigrams", z0);

        virtualinvoke $r6.<org.apache.hadoop.conf.Configuration: void setInt(java.lang.String,int)>("maxShingleSize", i0);

        virtualinvoke $r6.<org.apache.hadoop.conf.Configuration: void setInt(java.lang.String,int)>("minSupport", i2);

        $r7 = new org.apache.hadoop.mapreduce.Job;

        specialinvoke $r7.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration)>($r6);

        $r8 = new java.lang.StringBuilder;

        specialinvoke $r8.<java.lang.StringBuilder: void <init>()>();

        $r9 = class "org/apache/mahout/vectorizer/collocations/llr/CollocDriver";

        $r10 = virtualinvoke $r9.<java.lang.Class: java.lang.String getSimpleName()>();

        $r12 = virtualinvoke $r8.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>($r10);

        $r11 = virtualinvoke $r12.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(".generateCollocations:");

        $r14 = virtualinvoke $r11.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.Object)>(r0);

        $r13 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.String toString()>();

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setJobName(java.lang.String)>($r13);

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/CollocDriver");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setMapOutputKeyClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/GramKey");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setMapOutputValueClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/Gram");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setPartitionerClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/GramKeyPartitioner");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setGroupingComparatorClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/GramKeyGroupComparator");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/Gram");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/Gram");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/CollocCombiner");

        $r16 = newarray (org.apache.hadoop.fs.Path)[1];

        $r16[0] = r0;

        staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void setInputPaths(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path[])>($r7, $r16);

        $r15 = new org.apache.hadoop.fs.Path;

        specialinvoke $r15.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>(r1, "subgrams");

        staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>($r7, $r15);

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setInputFormatClass(java.lang.Class)>(class "org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFormat");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/CollocMapper");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setOutputFormatClass(java.lang.Class)>(class "org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/CollocReducer");

        virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: void setNumReduceTasks(int)>(i1);

        z1 = virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1);

        if z1 != 0 goto label1;

        $r20 = new java.lang.IllegalStateException;

        specialinvoke $r20.<java.lang.IllegalStateException: void <init>(java.lang.String)>("Job failed!");

        throw $r20;

     label1:
        $r17 = virtualinvoke $r7.<org.apache.hadoop.mapreduce.Job: org.apache.hadoop.mapreduce.Counters getCounters()>();

        $r19 = <org.apache.mahout.vectorizer.collocations.llr.CollocMapper$Count: org.apache.mahout.vectorizer.collocations.llr.CollocMapper$Count NGRAM_TOTAL>;

        $r18 = virtualinvoke $r17.<org.apache.hadoop.mapreduce.Counters: org.apache.hadoop.mapreduce.Counter findCounter(java.lang.Enum)>($r19);

        $l3 = interfaceinvoke $r18.<org.apache.hadoop.mapreduce.Counter: long getValue()>();

        return $l3;
    }

    private static void computeNGramsPruneByLLR(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, long, boolean, float, int) throws java.io.IOException, java.lang.InterruptedException, java.lang.ClassNotFoundException
    {
        org.apache.hadoop.fs.Path r0, $r14, $r16;
        org.apache.hadoop.conf.Configuration r1, $r5;
        long l0;
        boolean z0, z1;
        float f0;
        int i1;
        org.apache.hadoop.mapreduce.Job $r6;
        java.lang.StringBuilder $r7, $r10, $r11, $r13;
        java.lang.Class $r8;
        java.lang.String $r9, $r12;
        org.apache.hadoop.fs.Path[] $r15;
        java.lang.IllegalStateException $r17;

        r0 := @parameter0: org.apache.hadoop.fs.Path;

        r1 := @parameter1: org.apache.hadoop.conf.Configuration;

        l0 := @parameter2: long;

        z0 := @parameter3: boolean;

        f0 := @parameter4: float;

        i1 := @parameter5: int;

        $r5 = new org.apache.hadoop.conf.Configuration;

        specialinvoke $r5.<org.apache.hadoop.conf.Configuration: void <init>(org.apache.hadoop.conf.Configuration)>(r1);

        virtualinvoke $r5.<org.apache.hadoop.conf.Configuration: void setLong(java.lang.String,long)>("ngramTotal", l0);

        virtualinvoke $r5.<org.apache.hadoop.conf.Configuration: void setBoolean(java.lang.String,boolean)>("emit-unigrams", z0);

        virtualinvoke $r5.<org.apache.hadoop.conf.Configuration: void setFloat(java.lang.String,float)>("minLLR", f0);

        $r6 = new org.apache.hadoop.mapreduce.Job;

        specialinvoke $r6.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration)>($r5);

        $r7 = new java.lang.StringBuilder;

        specialinvoke $r7.<java.lang.StringBuilder: void <init>()>();

        $r8 = class "org/apache/mahout/vectorizer/collocations/llr/CollocDriver";

        $r9 = virtualinvoke $r8.<java.lang.Class: java.lang.String getSimpleName()>();

        $r11 = virtualinvoke $r7.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>($r9);

        $r10 = virtualinvoke $r11.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(".computeNGrams: ");

        $r13 = virtualinvoke $r10.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.Object)>(r0);

        $r12 = virtualinvoke $r13.<java.lang.StringBuilder: java.lang.String toString()>();

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setJobName(java.lang.String)>($r12);

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/CollocDriver");

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setMapOutputKeyClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/Gram");

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setMapOutputValueClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/Gram");

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text");

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/DoubleWritable");

        $r15 = newarray (org.apache.hadoop.fs.Path)[1];

        $r14 = new org.apache.hadoop.fs.Path;

        specialinvoke $r14.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>(r0, "subgrams");

        $r15[0] = $r14;

        staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void setInputPaths(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path[])>($r6, $r15);

        $r16 = new org.apache.hadoop.fs.Path;

        specialinvoke $r16.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>(r0, "ngrams");

        staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>($r6, $r16);

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "org/apache/hadoop/mapreduce/Mapper");

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setInputFormatClass(java.lang.Class)>(class "org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFormat");

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setOutputFormatClass(java.lang.Class)>(class "org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat");

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/LLRReducer");

        virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: void setNumReduceTasks(int)>(i1);

        z1 = virtualinvoke $r6.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1);

        if z1 != 0 goto label1;

        $r17 = new java.lang.IllegalStateException;

        specialinvoke $r17.<java.lang.IllegalStateException: void <init>(java.lang.String)>("Job failed!");

        throw $r17;

     label1:
        return;
    }

    static void <clinit>()
    {
        org.slf4j.Logger $r0;

        <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: int DEFAULT_PASS1_NUM_REDUCE_TASKS> = 1;

        <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: int DEFAULT_MAX_NGRAM_SIZE> = 2;

        <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: boolean DEFAULT_EMIT_UNIGRAMS> = 0;

        <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String EMIT_UNIGRAMS> = "emit-unigrams";

        <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String NGRAM_OUTPUT_DIRECTORY> = "ngrams";

        <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: java.lang.String SUBGRAM_OUTPUT_DIRECTORY> = "subgrams";

        $r0 = staticinvoke <org.slf4j.LoggerFactory: org.slf4j.Logger getLogger(java.lang.Class)>(class "org/apache/mahout/vectorizer/collocations/llr/CollocDriver");

        <org.apache.mahout.vectorizer.collocations.llr.CollocDriver: org.slf4j.Logger log> = $r0;

        return;
    }
}
