public final class org.apache.mahout.clustering.classify.ClusterClassificationDriver extends org.apache.mahout.common.AbstractJob
{

    public int run(java.lang.String[]) throws java.lang.Exception
    {
        org.apache.mahout.clustering.classify.ClusterClassificationDriver r0;
        java.lang.String[] r1;
        org.apache.hadoop.fs.Path r2, r3, $r13;
        boolean z0, $z1;
        org.apache.commons.cli2.builder.DefaultOptionBuilder $r5, $r8, $r9;
        org.apache.commons.cli2.option.DefaultOption $r6, $r10;
        java.util.Map $r12;
        org.apache.hadoop.conf.Configuration $r14, $r18, $r19;
        java.lang.String $r15, $r16, $r17;
        double d0;

        r0 := @this: org.apache.mahout.clustering.classify.ClusterClassificationDriver;

        r1 := @parameter0: java.lang.String[];

        virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: void addInputOption()>();

        virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: void addOutputOption()>();

        $r5 = staticinvoke <org.apache.mahout.common.commandline.DefaultOptionCreator: org.apache.commons.cli2.builder.DefaultOptionBuilder methodOption()>();

        $r6 = virtualinvoke $r5.<org.apache.commons.cli2.builder.DefaultOptionBuilder: org.apache.commons.cli2.option.DefaultOption create()>();

        virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: org.apache.commons.cli2.Option addOption(org.apache.commons.cli2.Option)>($r6);

        $r8 = staticinvoke <org.apache.mahout.common.commandline.DefaultOptionCreator: org.apache.commons.cli2.builder.DefaultOptionBuilder clustersInOption()>();

        $r9 = virtualinvoke $r8.<org.apache.commons.cli2.builder.DefaultOptionBuilder: org.apache.commons.cli2.builder.DefaultOptionBuilder withDescription(java.lang.String)>("The input centroids, as Vectors.  Must be a SequenceFile of Writable, Cluster/Canopy.");

        $r10 = virtualinvoke $r9.<org.apache.commons.cli2.builder.DefaultOptionBuilder: org.apache.commons.cli2.option.DefaultOption create()>();

        virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: org.apache.commons.cli2.Option addOption(org.apache.commons.cli2.Option)>($r10);

        $r12 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: java.util.Map parseArguments(java.lang.String[])>(r1);

        if $r12 != null goto label1;

        return -1;

     label1:
        r2 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: org.apache.hadoop.fs.Path getInputPath()>();

        r3 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: org.apache.hadoop.fs.Path getOutputPath()>();

        $r14 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: org.apache.hadoop.conf.Configuration getConf()>();

        if $r14 != null goto label2;

        $r19 = new org.apache.hadoop.conf.Configuration;

        specialinvoke $r19.<org.apache.hadoop.conf.Configuration: void <init>()>();

        virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: void setConf(org.apache.hadoop.conf.Configuration)>($r19);

     label2:
        $r13 = new org.apache.hadoop.fs.Path;

        $r16 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: java.lang.String getOption(java.lang.String)>("clusters");

        specialinvoke $r13.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r16);

        $r15 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: java.lang.String getOption(java.lang.String)>("method");

        z0 = virtualinvoke $r15.<java.lang.String: boolean equalsIgnoreCase(java.lang.String)>("sequential");

        d0 = 0.0;

        $z1 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: boolean hasOption(java.lang.String)>("outlierThreshold");

        if $z1 == 0 goto label3;

        $r17 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: java.lang.String getOption(java.lang.String)>("outlierThreshold");

        d0 = staticinvoke <java.lang.Double: double parseDouble(java.lang.String)>($r17);

     label3:
        $r18 = virtualinvoke r0.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: org.apache.hadoop.conf.Configuration getConf()>();

        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void run(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,double,boolean,boolean)>($r18, r2, $r13, r3, d0, 1, z0);

        return 0;
    }

    private void <init>()
    {
        org.apache.mahout.clustering.classify.ClusterClassificationDriver r0;

        r0 := @this: org.apache.mahout.clustering.classify.ClusterClassificationDriver;

        specialinvoke r0.<org.apache.mahout.common.AbstractJob: void <init>()>();

        return;
    }

    public static void main(java.lang.String[]) throws java.lang.Exception
    {
        java.lang.String[] r0;
        org.apache.hadoop.conf.Configuration $r1;
        org.apache.mahout.clustering.classify.ClusterClassificationDriver $r2;

        r0 := @parameter0: java.lang.String[];

        $r1 = new org.apache.hadoop.conf.Configuration;

        specialinvoke $r1.<org.apache.hadoop.conf.Configuration: void <init>()>();

        $r2 = new org.apache.mahout.clustering.classify.ClusterClassificationDriver;

        specialinvoke $r2.<org.apache.mahout.clustering.classify.ClusterClassificationDriver: void <init>()>();

        staticinvoke <org.apache.hadoop.util.ToolRunner: int run(org.apache.hadoop.conf.Configuration,org.apache.hadoop.util.Tool,java.lang.String[])>($r1, $r2, r0);

        return;
    }

    public static void run(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, java.lang.Double, boolean, boolean) throws java.io.IOException, java.lang.InterruptedException, java.lang.ClassNotFoundException
    {
        org.apache.hadoop.conf.Configuration r0;
        org.apache.hadoop.fs.Path r1, r2, r3;
        java.lang.Double r4;
        boolean z0, z1;

        r0 := @parameter0: org.apache.hadoop.conf.Configuration;

        r1 := @parameter1: org.apache.hadoop.fs.Path;

        r2 := @parameter2: org.apache.hadoop.fs.Path;

        r3 := @parameter3: org.apache.hadoop.fs.Path;

        r4 := @parameter4: java.lang.Double;

        z0 := @parameter5: boolean;

        z1 := @parameter6: boolean;

        if z1 == 0 goto label1;

        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void classifyClusterSeq(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,java.lang.Double,boolean)>(r0, r1, r2, r3, r4, z0);

        goto label2;

     label1:
        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void classifyClusterMR(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,java.lang.Double,boolean)>(r0, r1, r2, r3, r4, z0);

     label2:
        return;
    }

    private static void classifyClusterSeq(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, java.lang.Double, boolean) throws java.io.IOException
    {
        org.apache.hadoop.conf.Configuration r0;
        org.apache.hadoop.fs.Path r1, r2, r3, $r8;
        java.lang.Double r4;
        boolean z0;
        java.util.List r5;
        org.apache.mahout.clustering.iterator.ClusteringPolicy r6;
        org.apache.mahout.clustering.classify.ClusterClassifier $r9;

        r0 := @parameter0: org.apache.hadoop.conf.Configuration;

        r1 := @parameter1: org.apache.hadoop.fs.Path;

        r2 := @parameter2: org.apache.hadoop.fs.Path;

        r3 := @parameter3: org.apache.hadoop.fs.Path;

        r4 := @parameter4: java.lang.Double;

        z0 := @parameter5: boolean;

        r5 = staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: java.util.List populateClusterModels(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)>(r2, r0);

        $r8 = staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: org.apache.hadoop.fs.Path finalClustersPath(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>(r0, r2);

        r6 = staticinvoke <org.apache.mahout.clustering.classify.ClusterClassifier: org.apache.mahout.clustering.iterator.ClusteringPolicy readPolicy(org.apache.hadoop.fs.Path)>($r8);

        $r9 = new org.apache.mahout.clustering.classify.ClusterClassifier;

        specialinvoke $r9.<org.apache.mahout.clustering.classify.ClusterClassifier: void <init>(java.util.List,org.apache.mahout.clustering.iterator.ClusteringPolicy)>(r5, r6);

        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void selectCluster(org.apache.hadoop.fs.Path,java.util.List,org.apache.mahout.clustering.classify.ClusterClassifier,org.apache.hadoop.fs.Path,java.lang.Double,boolean)>(r1, r5, $r9, r3, r4, z0);

        return;
    }

    private static java.util.List populateClusterModels(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration) throws java.io.IOException
    {
        org.apache.hadoop.fs.Path r0, r3;
        org.apache.hadoop.conf.Configuration r1;
        org.apache.mahout.clustering.iterator.ClusterWritable r5;
        org.apache.mahout.clustering.Cluster r6;
        java.util.ArrayList $r7;
        org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterator $r8;
        org.apache.mahout.common.iterator.sequencefile.PathType $r9;
        org.apache.hadoop.fs.PathFilter $r10;
        boolean $z0;
        java.lang.Object $r11;

        r0 := @parameter0: org.apache.hadoop.fs.Path;

        r1 := @parameter1: org.apache.hadoop.conf.Configuration;

        $r7 = new java.util.ArrayList;

        specialinvoke $r7.<java.util.ArrayList: void <init>()>();

        r3 = staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: org.apache.hadoop.fs.Path finalClustersPath(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>(r1, r0);

        $r8 = new org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterator;

        $r9 = <org.apache.mahout.common.iterator.sequencefile.PathType: org.apache.mahout.common.iterator.sequencefile.PathType LIST>;

        $r10 = staticinvoke <org.apache.mahout.common.iterator.sequencefile.PathFilters: org.apache.hadoop.fs.PathFilter partFilter()>();

        specialinvoke $r8.<org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterator: void <init>(org.apache.hadoop.fs.Path,org.apache.mahout.common.iterator.sequencefile.PathType,org.apache.hadoop.fs.PathFilter,java.util.Comparator,boolean,org.apache.hadoop.conf.Configuration)>(r3, $r9, $r10, null, 0, r1);

     label1:
        $z0 = interfaceinvoke $r8.<java.util.Iterator: boolean hasNext()>();

        if $z0 == 0 goto label2;

        $r11 = interfaceinvoke $r8.<java.util.Iterator: java.lang.Object next()>();

        r5 = (org.apache.mahout.clustering.iterator.ClusterWritable) $r11;

        r6 = virtualinvoke r5.<org.apache.mahout.clustering.iterator.ClusterWritable: org.apache.mahout.clustering.Cluster getValue()>();

        interfaceinvoke r6.<org.apache.mahout.clustering.Cluster: void configure(org.apache.hadoop.conf.Configuration)>(r1);

        interfaceinvoke $r7.<java.util.List: boolean add(java.lang.Object)>(r6);

        goto label1;

     label2:
        return $r7;
    }

    private static org.apache.hadoop.fs.Path finalClustersPath(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path) throws java.io.IOException
    {
        org.apache.hadoop.conf.Configuration r0;
        org.apache.hadoop.fs.Path r1, $r6;
        org.apache.hadoop.fs.FileSystem r2;
        org.apache.hadoop.fs.FileStatus[] r3;
        org.apache.hadoop.fs.PathFilter $r4;
        org.apache.hadoop.fs.FileStatus $r5;

        r0 := @parameter0: org.apache.hadoop.conf.Configuration;

        r1 := @parameter1: org.apache.hadoop.fs.Path;

        r2 = virtualinvoke r1.<org.apache.hadoop.fs.Path: org.apache.hadoop.fs.FileSystem getFileSystem(org.apache.hadoop.conf.Configuration)>(r0);

        $r4 = staticinvoke <org.apache.mahout.common.iterator.sequencefile.PathFilters: org.apache.hadoop.fs.PathFilter finalPartFilter()>();

        r3 = virtualinvoke r2.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)>(r1, $r4);

        $r5 = r3[0];

        $r6 = virtualinvoke $r5.<org.apache.hadoop.fs.FileStatus: org.apache.hadoop.fs.Path getPath()>();

        return $r6;
    }

    private static void selectCluster(org.apache.hadoop.fs.Path, java.util.List, org.apache.mahout.clustering.classify.ClusterClassifier, org.apache.hadoop.fs.Path, java.lang.Double, boolean) throws java.io.IOException
    {
        org.apache.hadoop.fs.Path r0, r3, $r15;
        java.util.List r1;
        org.apache.mahout.clustering.classify.ClusterClassifier r2;
        java.lang.Double r4;
        boolean z0, $z1, $z2, $z3, $z4, $z5;
        java.util.Iterator r7;
        org.apache.mahout.common.Pair r8;
        java.lang.Class r9;
        org.apache.mahout.math.Vector r10, r32;
        org.apache.hadoop.conf.Configuration $r11;
        org.apache.hadoop.io.SequenceFile$Writer $r12;
        org.apache.hadoop.fs.FileSystem $r13;
        org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable $r14;
        org.apache.hadoop.fs.PathFilter $r16;
        org.apache.mahout.common.iterator.sequencefile.PathType $r17;
        java.lang.Object $r18, $r19, $r22, $r26, $r27;
        org.apache.hadoop.io.Writable $r20, $r28;
        org.apache.mahout.math.VectorWritable $r21, $r23;
        org.apache.hadoop.io.IntWritable $r24;
        int $i0;
        org.apache.mahout.math.NamedVector $r25, $r30;
        java.lang.String $r29, $r31;

        r0 := @parameter0: org.apache.hadoop.fs.Path;

        r1 := @parameter1: java.util.List;

        r2 := @parameter2: org.apache.mahout.clustering.classify.ClusterClassifier;

        r3 := @parameter3: org.apache.hadoop.fs.Path;

        r4 := @parameter4: java.lang.Double;

        z0 := @parameter5: boolean;

        $r11 = new org.apache.hadoop.conf.Configuration;

        specialinvoke $r11.<org.apache.hadoop.conf.Configuration: void <init>()>();

        $r12 = new org.apache.hadoop.io.SequenceFile$Writer;

        $r13 = virtualinvoke r0.<org.apache.hadoop.fs.Path: org.apache.hadoop.fs.FileSystem getFileSystem(org.apache.hadoop.conf.Configuration)>($r11);

        $r15 = new org.apache.hadoop.fs.Path;

        specialinvoke $r15.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>(r3, "part-m-0");

        specialinvoke $r12.<org.apache.hadoop.io.SequenceFile$Writer: void <init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class)>($r13, $r11, $r15, class "org/apache/hadoop/io/IntWritable", class "org/apache/mahout/clustering/classify/WeightedPropertyVectorWritable");

        $r14 = new org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable;

        $r17 = <org.apache.mahout.common.iterator.sequencefile.PathType: org.apache.mahout.common.iterator.sequencefile.PathType LIST>;

        $r16 = staticinvoke <org.apache.mahout.common.iterator.sequencefile.PathFilters: org.apache.hadoop.fs.PathFilter logsCRCFilter()>();

        specialinvoke $r14.<org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable: void <init>(org.apache.hadoop.fs.Path,org.apache.mahout.common.iterator.sequencefile.PathType,org.apache.hadoop.fs.PathFilter,org.apache.hadoop.conf.Configuration)>(r0, $r17, $r16, $r11);

        r7 = virtualinvoke $r14.<org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable: java.util.Iterator iterator()>();

     label1:
        $z1 = interfaceinvoke r7.<java.util.Iterator: boolean hasNext()>();

        if $z1 == 0 goto label4;

        $r19 = interfaceinvoke r7.<java.util.Iterator: java.lang.Object next()>();

        r8 = (org.apache.mahout.common.Pair) $r19;

        $r18 = virtualinvoke r8.<org.apache.mahout.common.Pair: java.lang.Object getFirst()>();

        $r20 = (org.apache.hadoop.io.Writable) $r18;

        r9 = virtualinvoke $r20.<java.lang.Object: java.lang.Class getClass()>();

        $r22 = virtualinvoke r8.<org.apache.mahout.common.Pair: java.lang.Object getSecond()>();

        $r21 = (org.apache.mahout.math.VectorWritable) $r22;

        r32 = virtualinvoke $r21.<org.apache.mahout.math.VectorWritable: org.apache.mahout.math.Vector get()>();

        $z2 = virtualinvoke r9.<java.lang.Object: boolean equals(java.lang.Object)>(class "org/apache/mahout/math/NamedVector");

        if $z2 != 0 goto label3;

        $z3 = virtualinvoke r9.<java.lang.Object: boolean equals(java.lang.Object)>(class "org/apache/hadoop/io/Text");

        if $z3 == 0 goto label2;

        $r30 = new org.apache.mahout.math.NamedVector;

        $r27 = virtualinvoke r8.<org.apache.mahout.common.Pair: java.lang.Object getFirst()>();

        $r28 = (org.apache.hadoop.io.Writable) $r27;

        $r31 = virtualinvoke $r28.<java.lang.Object: java.lang.String toString()>();

        specialinvoke $r30.<org.apache.mahout.math.NamedVector: void <init>(org.apache.mahout.math.Vector,java.lang.String)>(r32, $r31);

        r32 = $r30;

        goto label3;

     label2:
        $z4 = virtualinvoke r9.<java.lang.Object: boolean equals(java.lang.Object)>(class "org/apache/hadoop/io/IntWritable");

        if $z4 == 0 goto label3;

        $r25 = new org.apache.mahout.math.NamedVector;

        $r26 = virtualinvoke r8.<org.apache.mahout.common.Pair: java.lang.Object getFirst()>();

        $r24 = (org.apache.hadoop.io.IntWritable) $r26;

        $i0 = virtualinvoke $r24.<org.apache.hadoop.io.IntWritable: int get()>();

        $r29 = staticinvoke <java.lang.Integer: java.lang.String toString(int)>($i0);

        specialinvoke $r25.<org.apache.mahout.math.NamedVector: void <init>(org.apache.mahout.math.Vector,java.lang.String)>(r32, $r29);

        r32 = $r25;

     label3:
        r10 = virtualinvoke r2.<org.apache.mahout.clustering.classify.ClusterClassifier: org.apache.mahout.math.Vector classify(org.apache.mahout.math.Vector)>(r32);

        $z5 = staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: boolean shouldClassify(org.apache.mahout.math.Vector,java.lang.Double)>(r10, r4);

        if $z5 == 0 goto label1;

        $r23 = new org.apache.mahout.math.VectorWritable;

        specialinvoke $r23.<org.apache.mahout.math.VectorWritable: void <init>(org.apache.mahout.math.Vector)>(r32);

        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void classifyAndWrite(java.util.List,java.lang.Double,boolean,org.apache.hadoop.io.SequenceFile$Writer,org.apache.mahout.math.VectorWritable,org.apache.mahout.math.Vector)>(r1, r4, z0, $r12, $r23, r10);

        goto label1;

     label4:
        virtualinvoke $r12.<org.apache.hadoop.io.SequenceFile$Writer: void close()>();

        return;
    }

    private static void classifyAndWrite(java.util.List, java.lang.Double, boolean, org.apache.hadoop.io.SequenceFile$Writer, org.apache.mahout.math.VectorWritable, org.apache.mahout.math.Vector) throws java.io.IOException
    {
        java.util.List r0;
        java.lang.Double r1;
        boolean z0;
        org.apache.hadoop.io.SequenceFile$Writer r2;
        org.apache.mahout.math.VectorWritable r3;
        org.apache.mahout.math.Vector r4, $r9;
        int i0;
        java.util.HashMap $r7;
        org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable $r8;
        double $d0;

        r0 := @parameter0: java.util.List;

        r1 := @parameter1: java.lang.Double;

        z0 := @parameter2: boolean;

        r2 := @parameter3: org.apache.hadoop.io.SequenceFile$Writer;

        r3 := @parameter4: org.apache.mahout.math.VectorWritable;

        r4 := @parameter5: org.apache.mahout.math.Vector;

        $r7 = new java.util.HashMap;

        specialinvoke $r7.<java.util.HashMap: void <init>()>();

        if z0 == 0 goto label1;

        i0 = interfaceinvoke r4.<org.apache.mahout.math.Vector: int maxValueIndex()>();

        $r8 = new org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable;

        $d0 = interfaceinvoke r4.<org.apache.mahout.math.Vector: double maxValue()>();

        $r9 = virtualinvoke r3.<org.apache.mahout.math.VectorWritable: org.apache.mahout.math.Vector get()>();

        specialinvoke $r8.<org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable: void <init>(double,org.apache.mahout.math.Vector,java.util.Map)>($d0, $r9, $r7);

        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void write(java.util.List,org.apache.hadoop.io.SequenceFile$Writer,org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable,int)>(r0, r2, $r8, i0);

        goto label2;

     label1:
        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void writeAllAboveThreshold(java.util.List,java.lang.Double,org.apache.hadoop.io.SequenceFile$Writer,org.apache.mahout.math.VectorWritable,org.apache.mahout.math.Vector)>(r0, r1, r2, r3, r4);

     label2:
        return;
    }

    private static void writeAllAboveThreshold(java.util.List, java.lang.Double, org.apache.hadoop.io.SequenceFile$Writer, org.apache.mahout.math.VectorWritable, org.apache.mahout.math.Vector) throws java.io.IOException
    {
        java.util.List r0;
        java.lang.Double r1;
        org.apache.hadoop.io.SequenceFile$Writer r2;
        org.apache.mahout.math.VectorWritable r3;
        org.apache.mahout.math.Vector r4, $r13;
        java.util.Iterator r6;
        org.apache.mahout.math.Vector$Element r7;
        int i0;
        java.util.HashMap $r9;
        java.lang.Iterable $r10;
        boolean $z0;
        java.lang.Object $r11;
        double $d0, $d1, $d2;
        byte $b1;
        org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable $r12;

        r0 := @parameter0: java.util.List;

        r1 := @parameter1: java.lang.Double;

        r2 := @parameter2: org.apache.hadoop.io.SequenceFile$Writer;

        r3 := @parameter3: org.apache.mahout.math.VectorWritable;

        r4 := @parameter4: org.apache.mahout.math.Vector;

        $r9 = new java.util.HashMap;

        specialinvoke $r9.<java.util.HashMap: void <init>()>();

        $r10 = interfaceinvoke r4.<org.apache.mahout.math.Vector: java.lang.Iterable nonZeroes()>();

        r6 = interfaceinvoke $r10.<java.lang.Iterable: java.util.Iterator iterator()>();

     label1:
        $z0 = interfaceinvoke r6.<java.util.Iterator: boolean hasNext()>();

        if $z0 == 0 goto label2;

        $r11 = interfaceinvoke r6.<java.util.Iterator: java.lang.Object next()>();

        r7 = (org.apache.mahout.math.Vector$Element) $r11;

        $d0 = interfaceinvoke r7.<org.apache.mahout.math.Vector$Element: double get()>();

        $d1 = virtualinvoke r1.<java.lang.Double: double doubleValue()>();

        $b1 = $d0 cmpl $d1;

        if $b1 < 0 goto label1;

        $r12 = new org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable;

        $d2 = interfaceinvoke r7.<org.apache.mahout.math.Vector$Element: double get()>();

        $r13 = virtualinvoke r3.<org.apache.mahout.math.VectorWritable: org.apache.mahout.math.Vector get()>();

        specialinvoke $r12.<org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable: void <init>(double,org.apache.mahout.math.Vector,java.util.Map)>($d2, $r13, $r9);

        i0 = interfaceinvoke r7.<org.apache.mahout.math.Vector$Element: int index()>();

        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void write(java.util.List,org.apache.hadoop.io.SequenceFile$Writer,org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable,int)>(r0, r2, $r12, i0);

        goto label1;

     label2:
        return;
    }

    private static void write(java.util.List, org.apache.hadoop.io.SequenceFile$Writer, org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable, int) throws java.io.IOException
    {
        java.util.List r0;
        org.apache.hadoop.io.SequenceFile$Writer r1;
        org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable r2;
        int i0, $i1;
        org.apache.mahout.clustering.Cluster r3;
        org.apache.mahout.clustering.iterator.DistanceMeasureCluster r4;
        org.apache.mahout.common.distance.DistanceMeasure r5;
        double d0;
        java.lang.Object $r6;
        org.apache.mahout.math.Vector $r7, $r8;
        java.util.Map $r9;
        org.apache.hadoop.io.Text $r10, $r12;
        java.lang.String $r11;
        org.apache.hadoop.io.IntWritable $r13;

        r0 := @parameter0: java.util.List;

        r1 := @parameter1: org.apache.hadoop.io.SequenceFile$Writer;

        r2 := @parameter2: org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable;

        i0 := @parameter3: int;

        $r6 = interfaceinvoke r0.<java.util.List: java.lang.Object get(int)>(i0);

        r3 = (org.apache.mahout.clustering.Cluster) $r6;

        r4 = (org.apache.mahout.clustering.iterator.DistanceMeasureCluster) r3;

        r5 = virtualinvoke r4.<org.apache.mahout.clustering.iterator.DistanceMeasureCluster: org.apache.mahout.common.distance.DistanceMeasure getMeasure()>();

        $r7 = interfaceinvoke r3.<org.apache.mahout.clustering.Cluster: org.apache.mahout.math.Vector getCenter()>();

        $r8 = virtualinvoke r2.<org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable: org.apache.mahout.math.Vector getVector()>();

        d0 = interfaceinvoke r5.<org.apache.mahout.common.distance.DistanceMeasure: double distance(org.apache.mahout.math.Vector,org.apache.mahout.math.Vector)>($r7, $r8);

        $r9 = virtualinvoke r2.<org.apache.mahout.clustering.classify.WeightedPropertyVectorWritable: java.util.Map getProperties()>();

        $r10 = new org.apache.hadoop.io.Text;

        specialinvoke $r10.<org.apache.hadoop.io.Text: void <init>(java.lang.String)>("distance");

        $r12 = new org.apache.hadoop.io.Text;

        $r11 = staticinvoke <java.lang.Double: java.lang.String toString(double)>(d0);

        specialinvoke $r12.<org.apache.hadoop.io.Text: void <init>(java.lang.String)>($r11);

        interfaceinvoke $r9.<java.util.Map: java.lang.Object put(java.lang.Object,java.lang.Object)>($r10, $r12);

        $r13 = new org.apache.hadoop.io.IntWritable;

        $i1 = interfaceinvoke r3.<org.apache.mahout.clustering.Cluster: int getId()>();

        specialinvoke $r13.<org.apache.hadoop.io.IntWritable: void <init>(int)>($i1);

        virtualinvoke r1.<org.apache.hadoop.io.SequenceFile$Writer: void append(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)>($r13, r2);

        return;
    }

    private static boolean shouldClassify(org.apache.mahout.math.Vector, java.lang.Double)
    {
        org.apache.mahout.math.Vector r0;
        java.lang.Double r1;
        double $d0, $d1;
        byte $b0;
        boolean $z0;

        r0 := @parameter0: org.apache.mahout.math.Vector;

        r1 := @parameter1: java.lang.Double;

        $d0 = interfaceinvoke r0.<org.apache.mahout.math.Vector: double maxValue()>();

        $d1 = virtualinvoke r1.<java.lang.Double: double doubleValue()>();

        $b0 = $d0 cmpl $d1;

        if $b0 < 0 goto label1;

        $z0 = 1;

        goto label2;

     label1:
        $z0 = 0;

     label2:
        return $z0;
    }

    private static void classifyClusterMR(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, java.lang.Double, boolean) throws java.io.IOException, java.lang.InterruptedException, java.lang.ClassNotFoundException
    {
        org.apache.hadoop.conf.Configuration r0;
        org.apache.hadoop.fs.Path r1, r2, r3;
        java.lang.Double r4;
        boolean z0, $z1;
        float $f0;
        java.net.URI $r6;
        java.lang.String $r7, $r12, $r17;
        org.apache.hadoop.mapreduce.Job $r8;
        java.lang.StringBuilder $r9, $r10, $r11, $r13, $r15, $r16;
        java.lang.InterruptedException $r14;

        r0 := @parameter0: org.apache.hadoop.conf.Configuration;

        r1 := @parameter1: org.apache.hadoop.fs.Path;

        r2 := @parameter2: org.apache.hadoop.fs.Path;

        r3 := @parameter3: org.apache.hadoop.fs.Path;

        r4 := @parameter4: java.lang.Double;

        z0 := @parameter5: boolean;

        $f0 = virtualinvoke r4.<java.lang.Double: float floatValue()>();

        virtualinvoke r0.<org.apache.hadoop.conf.Configuration: void setFloat(java.lang.String,float)>("pdf_threshold", $f0);

        virtualinvoke r0.<org.apache.hadoop.conf.Configuration: void setBoolean(java.lang.String,boolean)>("emit_most_likely", z0);

        $r6 = virtualinvoke r2.<org.apache.hadoop.fs.Path: java.net.URI toUri()>();

        $r7 = virtualinvoke $r6.<java.net.URI: java.lang.String toString()>();

        virtualinvoke r0.<org.apache.hadoop.conf.Configuration: void set(java.lang.String,java.lang.String)>("clusters_in", $r7);

        $r8 = new org.apache.hadoop.mapreduce.Job;

        $r9 = new java.lang.StringBuilder;

        specialinvoke $r9.<java.lang.StringBuilder: void <init>()>();

        $r10 = virtualinvoke $r9.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Cluster Classification Driver running over input: ");

        $r11 = virtualinvoke $r10.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.Object)>(r1);

        $r12 = virtualinvoke $r11.<java.lang.StringBuilder: java.lang.String toString()>();

        specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r0, $r12);

        virtualinvoke $r8.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "org/apache/mahout/clustering/classify/ClusterClassificationDriver");

        virtualinvoke $r8.<org.apache.hadoop.mapreduce.Job: void setInputFormatClass(java.lang.Class)>(class "org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFormat");

        virtualinvoke $r8.<org.apache.hadoop.mapreduce.Job: void setOutputFormatClass(java.lang.Class)>(class "org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat");

        virtualinvoke $r8.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "org/apache/mahout/clustering/classify/ClusterClassificationMapper");

        virtualinvoke $r8.<org.apache.hadoop.mapreduce.Job: void setNumReduceTasks(int)>(0);

        virtualinvoke $r8.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable");

        virtualinvoke $r8.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/mahout/clustering/classify/WeightedPropertyVectorWritable");

        staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>($r8, r1);

        staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>($r8, r3);

        $z1 = virtualinvoke $r8.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1);

        if $z1 != 0 goto label1;

        $r14 = new java.lang.InterruptedException;

        $r13 = new java.lang.StringBuilder;

        specialinvoke $r13.<java.lang.StringBuilder: void <init>()>();

        $r16 = virtualinvoke $r13.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Cluster Classification Driver Job failed processing ");

        $r15 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.Object)>(r1);

        $r17 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.String toString()>();

        specialinvoke $r14.<java.lang.InterruptedException: void <init>(java.lang.String)>($r17);

        throw $r14;

     label1:
        return;
    }

    public static void run(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, double, boolean, boolean) throws java.io.IOException, java.lang.InterruptedException, java.lang.ClassNotFoundException
    {
        org.apache.hadoop.conf.Configuration r0;
        org.apache.hadoop.fs.Path r1, r2, r3;
        double d0;
        boolean z0, z1;
        java.lang.Double $r4, $r5;

        r0 := @parameter0: org.apache.hadoop.conf.Configuration;

        r1 := @parameter1: org.apache.hadoop.fs.Path;

        r2 := @parameter2: org.apache.hadoop.fs.Path;

        r3 := @parameter3: org.apache.hadoop.fs.Path;

        d0 := @parameter4: double;

        z0 := @parameter5: boolean;

        z1 := @parameter6: boolean;

        if z1 == 0 goto label1;

        $r5 = staticinvoke <java.lang.Double: java.lang.Double valueOf(double)>(d0);

        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void classifyClusterSeq(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,java.lang.Double,boolean)>(r0, r1, r2, r3, $r5, z0);

        goto label2;

     label1:
        $r4 = staticinvoke <java.lang.Double: java.lang.Double valueOf(double)>(d0);

        staticinvoke <org.apache.mahout.clustering.classify.ClusterClassificationDriver: void classifyClusterMR(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,java.lang.Double,boolean)>(r0, r1, r2, r3, $r4, z0);

     label2:
        return;
    }
}
