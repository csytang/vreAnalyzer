public class WordCount2 extends java.lang.Object
{

    public void <init>()
    {
        WordCount2 r0;

        r0 := @this;

        specialinvoke r0.<init>();

        return;
    }

    public static void main(java.lang.String[]) throws java.lang.Exception
    {
        java.lang.String[] r0, r4;
        org.apache.hadoop.mapreduce.Job r5, r6;
        org.apache.hadoop.conf.Configuration $r8, $r9, $r20, $r24;
        org.apache.hadoop.util.GenericOptionsParser $r10;
        int $i0, $i1, $i2, i3;
        java.util.ArrayList $r11;
        java.lang.String $r12, $r13, $r14, $r15, $r16, $r18, $r22, $r27, $r30, $r33, $r36;
        boolean $z0, $z1, $z3, $z4;
        org.apache.hadoop.fs.Path $r17, $r21, $r25, $r28, $r31, $r34;
        java.net.URI $r19, $r23;
        java.lang.Object $r26, $r29, $r32, $r35;
        java.io.PrintStream $r37;
        byte $b4;

        r0 := @parameter0;

        $r8 = new org.apache.hadoop.conf.Configuration;

        specialinvoke $r8.<init>();

        $r9 = new org.apache.hadoop.conf.Configuration;

        specialinvoke $r9.<init>();

        $r10 = new org.apache.hadoop.util.GenericOptionsParser;

        specialinvoke $r10.<init>($r8, r0);

        r4 = $r10.getRemainingArgs();

        $i0 = lengthof r4;

        if $i0 != 2 goto label1;

        $i2 = lengthof r4;

        if $i2 != 4 goto label1;

        $r37 = java.lang.System.err;

        $r37.println("Usage: wordcount <in> <out> [-skip skipPatternFile]");

        java.lang.System.exit(2);

     label1:
        r5 = org.apache.hadoop.mapreduce.Job.getInstance($r8, "word count");

        r5.setJarByClass(class "WordCount2");

        r5.setMapperClass(class "WordCount2$TokenizerMapper");

        r5.setCombinerClass(class "WordCount2$IntSumReducer");

        r5.setReducerClass(class "WordCount2$IntSumReducer");

        r5.setOutputKeyClass(class "org/apache/hadoop/io/Text");

        r5.setOutputValueClass(class "org/apache/hadoop/io/IntWritable");

        r6 = org.apache.hadoop.mapreduce.Job.getInstance($r9, "word count");

        r6.setJarByClass(class "WordCount2");

        r6.setMapperClass(class "WordCount2$TokenizerMapper");

        r6.setCombinerClass(class "WordCount2$IntSumReducer");

        r6.setReducerClass(class "WordCount2$IntSumReducer");

        r6.setOutputKeyClass(class "org/apache/hadoop/io/Text");

        r6.setOutputValueClass(class "org/apache/hadoop/io/IntWritable");

        $r11 = new java.util.ArrayList;

        specialinvoke $r11.<init>();

        i3 = 0;

        goto label6;

     label2:
        $r13 = "-skip";

        $r12 = r4[i3];

        $z0 = $r13.equals($r12);

        if $z0 == 0 goto label3;

        $r21 = new org.apache.hadoop.fs.Path;

        i3 = i3 + 1;

        $r22 = r4[i3];

        specialinvoke $r21.<init>($r22);

        $r23 = $r21.toUri();

        r5.addCacheFile($r23);

        $r24 = r5.getConfiguration();

        $r24.setBoolean("wordcount.skip.patterns", 1);

        goto label5;

     label3:
        $r15 = "-skip2";

        $r14 = r4[i3];

        $z1 = $r15.equals($r14);

        if $z1 == 0 goto label4;

        $r17 = new org.apache.hadoop.fs.Path;

        i3 = i3 + 1;

        $r18 = r4[i3];

        specialinvoke $r17.<init>($r18);

        $r19 = $r17.toUri();

        r6.addCacheFile($r19);

        $r20 = r6.getConfiguration();

        $r20.setBoolean("wordcount.skip.patterns", 1);

        goto label5;

     label4:
        $r16 = r4[i3];

        $r11.add($r16);

     label5:
        i3 = i3 + 1;

     label6:
        $i1 = lengthof r4;

        if i3 < $i1 goto label2;

        $r25 = new org.apache.hadoop.fs.Path;

        $r26 = $r11.get(0);

        $r27 = (java.lang.String) $r26;

        specialinvoke $r25.<init>($r27);

        org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPath(r5, $r25);

        $r28 = new org.apache.hadoop.fs.Path;

        $r29 = $r11.get(1);

        $r30 = (java.lang.String) $r29;

        specialinvoke $r28.<init>($r30);

        org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(r5, $r28);

        $r31 = new org.apache.hadoop.fs.Path;

        $r32 = $r11.get(0);

        $r33 = (java.lang.String) $r32;

        specialinvoke $r31.<init>($r33);

        org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPath(r6, $r31);

        $r34 = new org.apache.hadoop.fs.Path;

        $r35 = $r11.get(2);

        $r36 = (java.lang.String) $r35;

        specialinvoke $r34.<init>($r36);

        org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(r6, $r34);

        $z3 = r5.waitForCompletion(1);

        if $z3 == 0 goto label7;

        $z4 = r6.waitForCompletion(1);

        if $z4 == 0 goto label7;

        $b4 = 0;

        goto label8;

     label7:
        $b4 = 1;

     label8:
        java.lang.System.exit($b4);

        return;
    }
}
